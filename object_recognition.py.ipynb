{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object recognition in video using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was created to practhice object recognition in video stream using Convolutional Neural Networks (CNN). We can do this break the the problem in some steps:\n",
    "\n",
    "1. capture a video stream\n",
    "2. make pre processing and clean up data on frame image\n",
    "3. crop the region of an image\n",
    "4. use the cropped image in a CNN Model\n",
    "5. make predictions\n",
    "6. put a text with the correct label in the video\n",
    "\n",
    "We are using video streams, and make this predictions in the main loop is not a good idea. It can impact on the frame rates of the video.\n",
    "To solve this problem, we will put the recognition part in a thread.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "\n",
    "For this project we will use numpy, Keras, tensorflow (with keras), and OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "import image_utils\n",
    "import time\n",
    "import threading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an object for Video capture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `VideoStream` object is the object responsible to get the video and processing all the video frames. For each frame captured, it will preprocess the frame and keep the current frame available to predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoStream(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.frame = None\n",
    "        self.original = None\n",
    "        self.current_label = None\n",
    "\n",
    "    def start_video(self):\n",
    "        cap = cv2.VideoCapture('objects.avi')\n",
    "\n",
    "        while(cap.isOpened()):\n",
    "            time.sleep(0.1)\n",
    "            _, self.original = cap.read()\n",
    "            self.frame = cv2.resize(self.original, (224, 224))\n",
    "\n",
    "            # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # h,w,channels = self.original.shape\n",
    "            # self.frame = cv2.getRectSubPix(self.original, patchSize=(h,h), center=(w/2,h/2))\n",
    "            # self.frame = cv2.cvtColor(self.frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            cv2.putText(self.original, \n",
    "                        \"Object: {}\".format(self.current_label), \n",
    "                        (10, 60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.9, \n",
    "                        (0, 255, 0), \n",
    "                        2\n",
    "            )\n",
    "            cv2.imshow('Classification',self.original)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    def current_frame(self):\n",
    "        return self.frame\n",
    "\n",
    "\n",
    "    def write_label(self, label):\n",
    "        self.current_label = label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a thread task to object recognition\n",
    "\n",
    "As said before, the recognition taks will be perfomed by a Thread. The `RecognitionTask` will colaborate with `VideoStream` to get the current frame and apply it into the CNN model. For now, we will *Transfer Learning* with  pre trained imagenet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecognitionTask(threading.Thread):\n",
    "    def __init__(self, video_stream):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.video_stream = video_stream\n",
    "        self.model = VGG16(weights='imagenet')\n",
    "        self.graph = tf.get_default_graph()\n",
    "\n",
    "        # self.model = ResNet50(weights='imagenet')\n",
    "\n",
    "    def run(self):\n",
    "        frame = self.video_stream.current_frame()\n",
    "        while (~(frame is None)):\n",
    "            predictions = self.predict(frame)\n",
    "            label = predictions[1]\n",
    "            self.video_stream.write_label(label)\n",
    "            frame = self.video_stream.current_frame()\n",
    "    \n",
    "    def predict(self,frame):\n",
    "        if frame is None:\n",
    "            return '', ''\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        print image.shape\n",
    "        # image = image.transpose((2,0,1))\n",
    "        image = image.reshape((1,) + image.shape)\n",
    "        print image.shape\n",
    "        with self.graph.as_default():\n",
    "            image = image_utils.preprocess_input(image)\n",
    "            predictions = self.model.predict(image)\n",
    "            values = image_utils.decode_predictions(predictions)[0]\n",
    "            print values[0]\n",
    "            return values[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates a Command object\n",
    "\n",
    "The `Recognition` is a object that coordinate all the steps. It will be the object that starts the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recognition(object):\n",
    "\n",
    "    def start(self):\n",
    "        video_stream = VideoStream()\n",
    "        recognition_task = RecognitionTask(video_stream)\n",
    "        recognition_task.start()\n",
    "        video_stream.start_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03085013', u'computer_keyboard', 0.32429728)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03085013', u'computer_keyboard', 0.41292092)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03085013', u'computer_keyboard', 0.31177422)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03085013', u'computer_keyboard', 0.53773099)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04264628', u'space_bar', 0.45629096)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04264628', u'space_bar', 0.5214861)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03085013', u'computer_keyboard', 0.38137668)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03085013', u'computer_keyboard', 0.53222728)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03085013', u'computer_keyboard', 0.4133876)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04264628', u'space_bar', 0.40255386)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04264628', u'space_bar', 0.38903517)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04264628', u'space_bar', 0.40524644)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03085013', u'computer_keyboard', 0.37815109)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03085013', u'computer_keyboard', 0.44852492)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03085013', u'computer_keyboard', 0.42852691)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03085013', u'computer_keyboard', 0.48403677)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03085013', u'computer_keyboard', 0.45948797)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03085013', u'computer_keyboard', 0.45680135)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03085013', u'computer_keyboard', 0.50854099)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03085013', u'computer_keyboard', 0.44193083)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03085013', u'computer_keyboard', 0.24573706)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04120489', u'running_shoe', 0.54210317)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04120489', u'running_shoe', 0.8297348)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04120489', u'running_shoe', 0.8852632)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04120489', u'running_shoe', 0.90346634)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04120489', u'running_shoe', 0.96039009)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04120489', u'running_shoe', 0.97221595)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04120489', u'running_shoe', 0.97788733)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04120489', u'running_shoe', 0.97187084)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04120489', u'running_shoe', 0.95920604)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04120489', u'running_shoe', 0.95747054)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03483316', u'hand_blower', 0.64576983)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03483316', u'hand_blower', 0.69668901)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03483316', u'hand_blower', 0.57215488)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03483316', u'hand_blower', 0.94235671)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03483316', u'hand_blower', 0.91524744)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03483316', u'hand_blower', 0.93498325)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03483316', u'hand_blower', 0.92421877)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03483316', u'hand_blower', 0.93331313)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03483316', u'hand_blower', 0.96271044)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03483316', u'hand_blower', 0.94574106)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04116512', u'rubber_eraser', 0.051692721)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04548362', u'wallet', 0.13293637)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04548362', u'wallet', 0.23660962)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04548362', u'wallet', 0.15530264)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04548362', u'wallet', 0.1663603)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04548362', u'wallet', 0.21356548)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04548362', u'wallet', 0.17691559)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04548362', u'wallet', 0.16702694)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04548362', u'wallet', 0.21379054)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04548362', u'wallet', 0.24167921)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n04548362', u'wallet', 0.15790196)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-56c4f978a3ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrecognition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecognition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrecognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-e2aee3cd4d59>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mrecognition_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecognitionTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mrecognition_task\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mvideo_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-ba5e4927de64>\u001b[0m in \u001b[0;36mstart_video\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'n03777754', u'modem', 0.1261213)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03481172', u'hammer', 0.18077481)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03481172', u'hammer', 0.18077481)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03481172', u'hammer', 0.18077481)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03481172', u'hammer', 0.18077481)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03481172', u'hammer', 0.18077481)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03481172', u'hammer', 0.18077481)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03481172', u'hammer', 0.18077481)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03481172', u'hammer', 0.18077481)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03481172', u'hammer', 0.18077481)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03481172', u'hammer', 0.18077481)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03481172', u'hammer', 0.18077481)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(u'n03481172', u'hammer', 0.18077481)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "recognition = Recognition()\n",
    "recognition.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
